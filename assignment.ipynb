{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import RecordVideo\n",
    "gymlogger.set_level(40) #error only\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "import pygame\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\"\n",
    "            #    , render_mode=\"human\"\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is observation space: <class 'gym.spaces.box.Box'>\n",
      "this is action space: Discrete(2)\n",
      "this is observation space high: [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "this is observation space low: [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n",
      "[9.600000381469727, 6.805646932770577e+38, 0.8377580642700195, 6.805646932770577e+38]\n"
     ]
    }
   ],
   "source": [
    "print(f\"this is observation space: {type(env.observation_space)}\")\n",
    "print(f\"this is action space: {env.action_space}\")\n",
    "\n",
    "# 0: cart position 1: cart velocity 2: pole angle 3: pole angular velocity\n",
    "# observation high represents the highest value that the observation can take\n",
    "print(f\"this is observation space high: {env.observation_space.high}\")\n",
    "upper_bound = env.observation_space.high.tolist()\n",
    "\n",
    "# observation lowest represents the lowest value that the observation can take\n",
    "print(f\"this is observation space low: {env.observation_space.low}\")\n",
    "lower_bound = env.observation_space.low.tolist()\n",
    "\n",
    "# potentially changing\n",
    "span = [(upper_bound[i] - lower_bound[i]) for i in range(len(upper_bound))]\n",
    "print(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed() -> int:\n",
    "    return random.randint(0, 10000)\n",
    "\n",
    "seed = random_seed()\n",
    "print(f\"this is the seed: {seed}\")\n",
    "env.action_space.seed(seed)\n",
    "state = env.reset()[0]\n",
    "print(state)\n",
    "print(env.step(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depreciated\n",
    "def get_state(state: np.ndarray):\n",
    "    cart_position = state[0]\n",
    "    cart_velocity = state[1]\n",
    "    pole_angle = state[2] \n",
    "    pole_angular_velocity = state[3]\n",
    "    return cart_position, cart_velocity, pole_angle, pole_angular_velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: need to choose corresponding action according to state of the cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewards(action: int, cur_pos: List[float], next_pos: List[float]) -> int:\n",
    "    reward = 0\n",
    "\n",
    "    # action based on current state\n",
    "    if action == 0:\n",
    "        if cur_pos[0] > 0.5:\n",
    "            reward += 1\n",
    "        if cur_pos[1] > 0.25:\n",
    "            reward += 1\n",
    "        if cur_pos[2] > 0:\n",
    "            reward -= 100       # punishment for pole angle if it goes in wrong direction\n",
    "        if cur_pos[3] > 0.5:\n",
    "            reward -= 100       # punishment for pole angular velocity if it goes in wrong direction\n",
    "    elif action == 1:\n",
    "        if cur_pos[0] < -0.5:\n",
    "            reward += 1\n",
    "        if cur_pos[1] < -0.25:\n",
    "            reward += 1\n",
    "        if cur_pos[2] < 0:\n",
    "            reward -= 100\n",
    "        if cur_pos[3] < -0.5:\n",
    "            reward -= 100\n",
    "\n",
    "    # next state\n",
    "    reward += 1 if (-.25 < next_pos[0] < .25) else (0 if (-.5 < next_pos[0] < .5) else -1)\n",
    "    reward += 1 if (-.1 < next_pos[1] < .1) else (0 if (-.25 < next_pos[1] < .25) else -1)\n",
    "    reward += 5 if (-.05 < next_pos[2] < .05) else (0 if (-.1 < next_pos[2] < .1) else -5)\n",
    "    reward += 5 if (-.5 < next_pos[3] < .5) else (0 if (-1 < next_pos[3] < 1) else -5)\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_improvement() -> dict:\n",
    "    policy = {}\n",
    "    # for \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Iteration\n",
    "# the greek characters are generated from https://www.toptal.com/designers/htmlarrows/math/\n",
    "# π(s) = argmax_a Σ_s' P(s' | s, a) * (R(s) + γV(s'))\n",
    "def policy_iteration(gamma: float = 0.95, threshold: float = 1e-6) -> dict:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: run the RL agent 100 times, reset state at the start of each iteration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Render one episode played by the developed RL agent on Jupyter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SC3000",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
